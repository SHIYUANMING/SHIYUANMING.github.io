<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>SI251: Convex Optimization</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Yuanming Shi</div>
<div class="menu-item"><a href="home.html">Home</a></div>
<div class="menu-item"><a href="education.html">Education</a></div>
<div class="menu-item"><a href="research.html">Research</a></div>
<div class="menu-item"><a href="group.html">Group</a></div>
<div class="menu-item"><a href="idata.html">iData&nbsp;Lab</a></div>
<div class="menu-item"><a href="teaching.html" class="current">Teaching</a></div>
<div class="menu-item"><a href="publications.html">Publications</a></div>
<div class="menu-item"><a href="talks.html">Talks</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>SI251: Convex Optimization</h1>
<div id="subtitle"><a href="http://shiyuanming.github.io">Yuanming Shi</a>, ShanghaiTech University, Spring 2018</div>
</div>
<h2>Description</h2>
<p>This course provides a broad introduction to machine learning, statistical learning and deep learning, with particular emphasis on learning models, optimization algorithms and statistical analysis. Topics include: supervised learning (e.g., generative learning, parametric and nonparametric learning, regression, classification, support vector machines, neural networks); unsupervised learning (e.g., clustering, dimensionality reduction, kernel methods, density estimation); statistical learning theory (bias and variance tradeoffs; VC theory; large margins). This course will also introduce optimization methods (e.g., gradient methods, proximal methods, quasi-Newton methods, stochastic and randomized algorithms) that are suitable for large-scale problems arising in machine learning applications.</p>
<h2>Textbooks and Optional References</h2>
<p><b>Textbooks:</b></p>
<ul>
<li><p><a href="https://work.caltech.edu/telecourse.html"><i>Learning from Data</i></a>, by Yaser S. Abu-Mostafa, Malik Magdon-Ismail, and Hsuan-Tien Lin, AMLBook New York, 2012.</p>
</li>
<li><p><a href="http://stanford.edu/~boyd/cvxbook/"><i>Convex Optimization</i></a>, by S. Boyd and L. Vandenberghe, Cambridge University Press, 2003.</p>
</li>
</ul>
<p><b>References:</b></p>
<ul>
<li><p><a href="https://www.microsoft.com/en-us/research/people/cmbishop/?from=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fum%2Fpeople%2Fcmbishop%2F"><i>Pattern Recognition and Machine Learning</i></a>, by C. M. Bishop, Springer, 2007. </p>
</li>
<li><p><a href="https://web.stanford.edu/~hastie/ElemStatLearn/"><i>The Elements of Statistical Learning: Data Mining, Inference, and Prediction</i></a>, by T. Hastie, R. Tibshirani, and J. Friedman, Springer, 2009.</p>
</li>
<li><p><a href="http://www.deeplearningbook.org"><i>Deep Learning</i></a>, by I. Goodfellow, Y. Bengio and A. Courville, MIT Press, 2016. </p>
</li>
<li><p><a href="http://www.nowpublishers.com/article/Details/MAL-050"><i>Convex Optimization: Algorithms and Complexity</i></a>, by S. Bubeck, Foundations and Trends in Machine Learning, 2015.</p>
</li>
<li><p><a href="http://bookstore.siam.org/mo25/"><i>First-order Methods in Optimization</i></a>, by A. Beck, MOS-SIAM Series on Optimization, 2017.</p>
</li>
<li><p><a href="http://www.nowpublishers.com/article/Details/MAL-058"><i>Non-convex Optimization for Machine Learning</i></a>, by P. Jain and P. Kark, Foundations and Trends in Machine Learning, 2017.</p>
</li>
</ul>
<h2>Lectures</h2>
<ol>
<li><p><b>Foundations</b></p>
<ol>
<li><p>The learning problem</p>
</li>
<li><p>Training versus testing</p>
</li>
<li><p>The linear model</p>
</li>
<li><p>Overfitting</p>
</li>
<li><p>Three learning principles</p>
</li></ol>
</li>
<li><p><b>Techniques</b></p>
<ol>
<li><p>Similarity-based methods</p>
</li>
<li><p>Neural networks</p>
</li>
<li><p>Support vector machines</p>
</li>
<li><p>Learning aides</p>
</li></ol>
</li>
<li><p><b>Optimization</b></p>
<ol>
<li><p>Convex and nonconvex optimization</p>
</li>
<li><p>First-order optimization algorithms</p>
</li>
<li><p>Second-order optimization algorithms</p>
</li>
<li><p>Stochastic optimization algorithms</p>
</li>
</ol>

</li>
</ol>
<div id="footer">
<div id="footer-text">
Page generated 2018-01-13 17:39:30 CST, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
(<a href="ml.jemdoc">source</a>)
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
